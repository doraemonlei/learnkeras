{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#4机器学习基础\" data-toc-modified-id=\"4机器学习基础-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>4机器学习基础</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#4.4.2　添加权重正则化\" data-toc-modified-id=\"4.4.2　添加权重正则化-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>4.4.2　添加权重正则化</a></span></li><li><span><a href=\"#4.5.1　定义问题，收集数据集\" data-toc-modified-id=\"4.5.1　定义问题，收集数据集-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>4.5.1　定义问题，收集数据集</a></span></li><li><span><a href=\"#4.5.2　选择衡量成功的指标\" data-toc-modified-id=\"4.5.2　选择衡量成功的指标-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>4.5.2　选择衡量成功的指标</a></span></li><li><span><a href=\"#4.5.3　确定评估方法\" data-toc-modified-id=\"4.5.3　确定评估方法-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>4.5.3　确定评估方法</a></span></li><li><span><a href=\"#4.5.4　准备数据\" data-toc-modified-id=\"4.5.4　准备数据-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>4.5.4　准备数据</a></span></li><li><span><a href=\"#4.5.5　开发比基准更好的模型\" data-toc-modified-id=\"4.5.5　开发比基准更好的模型-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>4.5.5　开发比基准更好的模型</a></span></li><li><span><a href=\"#4.5.6　扩大模型规模：开发过拟合的模型\" data-toc-modified-id=\"4.5.6　扩大模型规模：开发过拟合的模型-1.0.7\"><span class=\"toc-item-num\">1.0.7&nbsp;&nbsp;</span>4.5.6　扩大模型规模：开发过拟合的模型</a></span></li><li><span><a href=\"#4.5.7　模型正则化与调节超参数\" data-toc-modified-id=\"4.5.7　模型正则化与调节超参数-1.0.8\"><span class=\"toc-item-num\">1.0.8&nbsp;&nbsp;</span>4.5.7　模型正则化与调节超参数</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4机器学习基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.1　机器学习的四个分支"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1.1　监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习是目前最常见的机器学习类型。给定一组样本（通常由人工标注），它可以学会将输入数据映射到已知目标［也叫标注（annotation）］。本书前面的四个例子都属于监督学习。一般来说，近年来广受关注的深度学习应用几乎都属于监督学习，比如光学字符识别、语音识别、图像分类和语言翻译。\n",
    "\n",
    "虽然监督学习主要包括分类和回归，但还有更多的奇特变体，主要包括如下几种。\n",
    "\n",
    "- 序列生成（sequence generation）。给定一张图像，预测描述图像的文字。序列生成有时可以被重新表示为一系列分类问题，比如反复预测序列中的单词或标记。\n",
    "- 语法树预测（syntax tree prediction）。给定一个句子，预测其分解生成的语法树。\n",
    "- 目标检测（object detection）。给定一张图像，在图中特定目标的周围画一个边界框。这个问题也可以表示为分类问题（给定多个候选边界框，对每个框内的目标进行分类）或分类与回归联合问题（用向量回归来预测边界框的坐标）。\n",
    "- 图像分割（image segmentation）。给定一张图像，在特定物体上画一个像素级的掩模（mask）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1.2　无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无监督学习是指在没有目标的情况下寻找输入数据的有趣变换，其目的在于数据可视化、\n",
    "数据压缩、数据去噪或更好地理解数据中的相关性。无监督学习是数据分析的必备技能，在解\n",
    "决监督学习问题之前，为了更好地了解数据集，它通常是一个必要步骤。降维（dimensionality\n",
    "reduction）和聚类（clustering）都是众所周知的无监督学习方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1.3　自监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "自监督学习是监督学习的一个特例，它与众不同，值得单独归为一类。自监督学习是没有\n",
    "人工标注的标签的监督学习，你可以将它看作没有人类参与的监督学习。标签仍然存在（因为\n",
    "总要有什么东西来监督学习过程），但它们是从输入数据中生成的，通常是使用启发式算法生\n",
    "成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.1.4　强化学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "在强化学习中，智能体（agent）接收有关其环境的信息，并学会选择使某种奖励最大化的行动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.2　评估机器学习模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "机器学习的目的是得到可以泛化（generalize）的模型，即在前所未见的数据上表现很好的\n",
    "模型，而过拟合则是核心难点。你只能控制可以观察的事情，所以能够可靠地衡量模型的泛化\n",
    "能力非常重要。后面几节将介绍降低过拟合以及将泛化能力最大化的方法。本节重点介绍如何\n",
    "衡量泛化能力，即如何评估机器学习模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2.1　训练集、验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "将数据划分为训练集、验证集和测试集可能看起来很简单，但如果可用数据很少，还有几\n",
    "种高级方法可以派上用场。我们先来介绍三种经典的评估方法：简单的留出验证、K 折验证，\n",
    "以及带有打乱数据的重复 K 折验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 简单的留出验证\n",
    "\n",
    "留出一定比例的数据作为测试集。在剩余的数据上训练模型，然后在测试集上评估模型。\n",
    "如前所述，为了防止信息泄露，你不能基于测试集来调节模型，所以还应该保留一个验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 10000\n",
    "np.random.shuffle(data)\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples:]\n",
    "training_data = data[:]\n",
    "\n",
    "# 在训练数据上训练模型，并在验证数据上评估模型\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# 现在你可以调节模型、重新训练、评估，然后再次调节……\n",
    "\n",
    "#一旦调节好超参数，通常就在所有非测试数据上从头开始训练最终模型\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,validation_data]))\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "这是最简单的评估方法，但有一个缺点：如果可用的数据很少，那么可能验证集和测试集\n",
    "包含的样本就太少，从而无法在统计学上代表数据。这个问题很容易发现：如果在划分数据前\n",
    "进行不同的随机打乱，最终得到的模型性能差别很大，那么就存在这个问题。接下来会介绍 K 折\n",
    "验证与重复的 K 折验证，它们是解决这一问题的两种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. K 折验证\n",
    "\n",
    "K 折验证（K-fold validation）将数据划分为大小相同的 K 个分区。对于每个分区 i ，在剩\n",
    "余的 K-1 个分区上训练模型，然后在分区 i 上评估模型。最终分数等于 K 个分数的平均值。对\n",
    "于不同的训练集 - 测试集划分，如果模型性能的变化很大，那么这种方法很有用。与留出验证\n",
    "一样，这种方法也需要独立的验证集进行模型校正。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold:num_validation_samples * (fold + 1)]\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "    \n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "# 在所有非测试数据上训练最终模型\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 带有打乱数据的重复 K 折验证\n",
    "\n",
    "如果可用的数据相对较少，而你又需要尽可能精确地评估模型，那么可以选择带有打乱数\n",
    "据的重复 K 折验证（iterated K-fold validation with shuffling）。我发现这种方法在 Kaggle 竞赛中\n",
    "特别有用。具体做法是多次使用 K 折验证，在每次将数据划分为 K 个分区之前都先将数据打乱。\n",
    "最终分数是每次 K 折验证分数的平均值。注意，这种方法一共要训练和评估 P×K 个模型（P\n",
    "是重复次数），计算代价很大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2.2　评估模型的注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据代表性（data representativeness）。你希望训练集和测试集都能够代表当前数据。例\n",
    "如，你想要对数字图像进行分类，而图像样本是按类别排序的，如果你将前 80% 作为训\n",
    "练集，剩余 20% 作为测试集，那么会导致训练集中只包含类别 0~7，而测试集中只包含\n",
    "类别 8~9。这个错误看起来很可笑，却很常见。因此，在将数据划分为训练集和测试集\n",
    "之前，通常应该随机打乱数据。\n",
    "- 时间箭头（the arrow of time）。如果想要根据过去预测未来（比如明天的天气、股票走势\n",
    "等），那么在划分数据前你不应该随机打乱数据，因为这么做会造成时间泄露（temporal\n",
    "leak）：你的模型将在未来数据上得到有效训练。在这种情况下，你应该始终确保测试集\n",
    "中所有数据的时间都晚于训练集数据。\n",
    "- 数据冗余（redundancy in your data）。如果数据中的某些数据点出现了两次（这在现实中\n",
    "的数据里十分常见），那么打乱数据并划分成训练集和验证集会导致训练集和验证集之\n",
    "间的数据冗余。从效果上来看，你是在部分训练数据上评估模型，这是极其糟糕的！一\n",
    "定要确保训练集和验证集之间没有交集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.3　数据预处理、特征工程和特征学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.3.1　神经网络的数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 向量化\n",
    "\n",
    "神经网络的所有输入和目标都必须是浮点数张量（在特定情况下可以是整数张量）。无论\n",
    "处理什么数据（声音、图像还是文本），都必须首先将其转换为张量，这一步叫作数据向量化\n",
    "（data vectorization）。例如，在前面两个文本分类的例子中，开始时文本都表示为整数列表（代\n",
    "表单词序列），然后我们用 one-hot 编码将其转换为 float32 格式的张量。在手写数字分类和预\n",
    "测房价的例子中，数据已经是向量形式，所以可以跳过这一步。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2. 值标准化\n",
    "\n",
    "- 取值较小：大部分值都应该在 0~1 范围内。\n",
    "- 同质性（homogenous）：所有特征的取值都应该在大致相同的范围内。\n",
    "\n",
    "此外，下面这种更严格的标准化方法也很常见，而且很有用，虽然不一定总是必需的（例如，\n",
    "对于数字分类问题就不需要这么做）。\n",
    "\n",
    "- 将每个特征分别标准化，使其平均值为 0。\n",
    "- 将每个特征分别标准化，使其标准差为 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 处理缺失值\n",
    "\n",
    "你的数据中有时可能会有缺失值。例如在房价的例子中，第一个特征（数据中索引编号为\n",
    "0 的列）是人均犯罪率。如果不是所有样本都具有这个特征的话，怎么办？那样你的训练数据\n",
    "或测试数据将会有缺失值。\n",
    "\n",
    "一般来说，对于神经网络，将缺失值设置为 0 是安全的，只要 0 不是一个有意义的值。网\n",
    "络能够从数据中学到 0 意味着缺失数据，并且会忽略这个值。\n",
    "\n",
    "注意，如果测试数据中可能有缺失值，而网络是在没有缺失值的数据上训练的，那么网络\n",
    "不可能学会忽略缺失值。在这种情况下，你应该人为生成一些有缺失项的训练样本：多次复制\n",
    "一些训练样本，然后删除测试数据中可能缺失的某些特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.3.2　特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习出现之前，特征工程曾经非常重要，因为经典的浅层算法没有足够大的假设空间\n",
    "来自己学习有用的表示。将数据呈现给算法的方式对解决问题至关重要。\n",
    "\n",
    "幸运的是，对于现代深度学习，大部分特征工程都是不需要的，因为神经网络能够从原始\n",
    "数据中自动提取有用的特征。这是否意味着，只要使用深度神经网络，就无须担心特征工程呢？\n",
    "并不是这样，原因有两点。\n",
    "\n",
    "- 良好的特征仍然可以让你用更少的资源更优雅地解决问题。例如，使用卷积神经网络来读取钟面上的时间是非常可笑的。\n",
    "- 良好的特征可以让你用更少的数据解决问题。深度学习模型自主学习特征的能力依赖于大量的训练数据。如果只有很少的样本，那么特征的信息价值就变得非常重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.4　过拟合与欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "机器学习的根本问题是优化和泛化之间的对立。优化（optimization）是指调节模型以在训\n",
    "练数据上得到最佳性能（即机器学习中的学习），而泛化（generalization）是指训练好的模型在\n",
    "前所未见的数据上的性能好坏。机器学习的目的当然是得到良好的泛化，但你无法控制泛化，\n",
    "只能基于训练数据调节模型。\n",
    "\n",
    "训练开始时，优化和泛化是相关的：训练数据上的损失越小，测试数据上的损失也越小。\n",
    "这时的模型是欠拟合（underfit）的，即仍有改进的空间，网络还没有对训练数据中所有相关模\n",
    "式建模。但在训练数据上迭代一定次数之后，泛化不再提高，验证指标先是不变，然后开始变差，\n",
    "即模型开始过拟合。这时模型开始学习仅和训练数据有关的模式，但这种模式对新数据来说是\n",
    "错误的或无关紧要的。\n",
    "\n",
    "为了防止模型从训练数据中学到错误或无关紧要的模式，最优解决方法是获取更多的训练\n",
    "数据。模型的训练数据越多，泛化能力自然也越好。如果无法获取更多数据，次优解决方法是\n",
    "调节模型允许存储的信息量，或对模型允许存储的信息加以约束。如果一个网络只能记住几个\n",
    "模式，那么优化过程会迫使模型集中学习最重要的模式，这样更可能得到良好的泛化。\n",
    "\n",
    "这种降低过拟合的方法叫作正则化（regularization）。我们先介绍几种最常见的正则化方法，\n",
    "然后将其应用于实践中，以改进 3.4 节的电影分类模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.4.1　减小网络大小\n",
    "\n",
    "防止过拟合的最简单的方法就是减小模型大小，即减少模型中可学习参数的个数（这由层\n",
    "数和每层的单元个数决定）。在深度学习中，模型中可学习参数的个数通常被称为模型的容量\n",
    "（capacity）。直观上来看，参数更多的模型拥有更大的记忆容量（memorization capacity），因此能\n",
    "够在训练样本和目标之间轻松地学会完美的字典式映射，这种映射没有任何泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.2　添加权重正则化\n",
    "\n",
    "你可能知道奥卡姆剃刀（Occam’s razor）原理：如果一件事情有两种解释，那么最可能正\n",
    "确的解释就是最简单的那个，即假设更少的那个。这个原理也适用于神经网络学到的模型：给\n",
    "定一些训练数据和一种网络架构，很多组权重值（即很多模型）都可以解释这些数据。简单模\n",
    "型比复杂模型更不容易过拟合。\n",
    "\n",
    "这里的简单模型（simple model）是指参数值分布的熵更小的模型（或参数更少的模型，比\n",
    "如上一节的例子）。因此，一种常见的降低过拟合的方法就是强制让模型权重只能取较小的值，\n",
    "从而限制模型的复杂度，这使得权重值的分布更加规则（regular）。这种方法叫作权重正则化\n",
    "（weight regularization），其实现方法是向网络损失函数中添加与较大权重值相关的成本（cost）。\n",
    "这个成本有两种形式。\n",
    "\n",
    "- L1 正则化（L1 regularization）：添加的成本与权重系数的绝对值［权重的 L1 范数（norm）］成正比。\n",
    "- L2 正则化（L2 regularization）：添加的成本与权重系数的平方（权重的 L2 范数）成正比。神经网络的 L2 正则化也叫权重衰减（weight decay）。不要被不同的名称搞混，权重衰减与 L2 正则化在数学上是完全相同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2(0.001) 的意思是该层权重矩阵的每个系数都会使网络总损失增加 0.001 * weight_\n",
    "coefficient_value 。注意，由于这个惩罚项只在训练时添加，所以这个网络的训练损失会\n",
    "比测试损失大很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.4.3　添加 dropout 正则化\n",
    "\n",
    "dropout 是神经网络最有效也最常用的正则化方法之一，它是由多伦多大学的 Geoffrey Hinton\n",
    "和他的学生开发的。对某一层使用 dropout，就是在训练过程中随机将该层的一些输出特征舍\n",
    "弃（设置为 0）。假设在训练过程中，某一层对给定输入样本的返回值应该是向量 [0.2, 0.5,\n",
    "1.3, 0.8, 1.1] 。使用 dropout 后，这个向量会有几个随机的元素变成 0，比如 [0, 0.5,\n",
    "1.3, 0, 1.1] 。dropout 比率（dropout rate）是被设为 0 的特征所占的比例，通常在 0.2~0.5\n",
    "范围内。测试时没有单元被舍弃，而该层的输出值需要按 dropout 比率缩小，因为这时比训练时\n",
    "有更多的单元被激活，需要加以平衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结一下，防止神经网络过拟合的常用方法包括：\n",
    "- 获取更多的训练数据\n",
    "- 减小网络容量\n",
    "- 添加权重正则化\n",
    "- 添加 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.5　机器学习的通用工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1　定义问题，收集数据集\n",
    "\n",
    "首先，你必须定义所面对的问题。\n",
    "- 你的输入数据是什么？你要预测什么？只有拥有可用的训练数据，你才能学习预测某件事情。比如，只有同时拥有电影评论和情感标注，你才能学习对电影评论进行情感分类。因此，数据可用性通常是这一阶段的限制因素（除非你有办法付钱让人帮你收集数据）。\n",
    "- 你面对的是什么类型的问题？是二分类问题、多分类问题、标量回归问题、向量回归问题，还是多分类、多标签问题？或者是其他问题，比如聚类、生成或强化学习？确定问题类型有助于你选择模型架构、损失函数等。\n",
    "\n",
    "只有明确了输入、输出以及所使用的数据，你才能进入下一阶段。注意你在这一阶段所做的假设。\n",
    "\n",
    "- 假设输出是可以根据输入进行预测的。\n",
    "- 假设可用数据包含足够多的信息，足以学习输入和输出之间的关系。\n",
    "\n",
    "在开发出工作模型之前，这些只是假设，等待验证真假。并非所有问题都可以解决。你收\n",
    "集了包含输入 X 和目标 Y 的很多样例，并不意味着 X 包含足够多的信息来预测 Y。例如，如果\n",
    "你想根据某支股票最近的历史价格来预测其股价走势，那你成功的可能性不大，因为历史价格\n",
    "并没有包含很多可用于预测的信息。\n",
    "\n",
    "有一类无法解决的问题你应该知道，那就是非平稳问题（nonstationary problem）。假设你想\n",
    "要构建一个服装推荐引擎，并在一个月（八月）的数据上训练，然后在冬天开始生成推荐结果。\n",
    "一个大问题是，人们购买服装的种类是随着季节变化的，即服装购买在几个月的尺度上是一个\n",
    "非平稳现象。你想要建模的对象随着时间推移而改变。在这种情况下，正确的做法是不断地利\n",
    "用最新数据重新训练模型，或者在一个问题是平稳的时间尺度上收集数据。对于服装购买这种\n",
    "周期性问题，几年的数据足以捕捉到季节性变化，但一定要记住，要将一年中的时间作为模型\n",
    "的一个输入。\n",
    "\n",
    "请记住，机器学习只能用来记忆训练数据中存在的模式。你只能识别出曾经见过的东西。\n",
    "在过去的数据上训练机器学习来预测未来，这里存在一个假设，就是未来的规律与过去相同。\n",
    "但事实往往并非如此。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2　选择衡量成功的指标\n",
    "\n",
    "要控制一件事物，就需要能够观察它。要取得成功，就必须给出成功的定义：精度？准确\n",
    "率（precision）和召回率（recall）？客户保留率？衡量成功的指标将指引你选择损失函数，即\n",
    "模型要优化什么。它应该直接与你的目标（如业务成功）保持一致。\n",
    "\n",
    "- 对于平衡分类问题（每个类别的可能性相同），精度和接收者操作特征曲线下面积（area under the receiver operating characteristic curve，ROC AUC）是常用的指标。\n",
    "- 对于类别不平衡的问题，你可以使用准确率和召回率。\n",
    "- 对于排序问题或多标签分类，你可以使用平均准确率均值（mean average precision）。\n",
    "- 自定义衡量成功的指标也很常见。\n",
    "\n",
    "要想了解各种机器学习的成功衡量指标以及这些指标与不同问题域的关系，你可以浏览 Kaggle 网站上的数据科学竞赛，上面展示了各种各样的问题和评估指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3　确定评估方法\n",
    "\n",
    "一旦明确了目标，你必须确定如何衡量当前的进展。前面介绍了三种常见的评估方法。\n",
    "- 留出验证集。数据量很大时可以采用这种方法。\n",
    "- K 折交叉验证。如果留出验证的样本量太少，无法保证可靠性，那么应该选择这种方法。\n",
    "- 重复的 K 折验证。如果可用的数据很少，同时模型评估又需要非常准确，那么应该使用\n",
    "这种方法。\n",
    "\n",
    "只需选择三者之一。大多数情况下，第一种方法足以满足要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.4　准备数据\n",
    "\n",
    "一旦知道了要训练什么、要优化什么以及评估方法，那么你就几乎已经准备好训练模型了。\n",
    "但首先你应该将数据格式化，使其可以输入到机器学习模型中（这里假设模型为深度神经网络）。\n",
    "\n",
    "- 如前所述，应该将数据格式化为张量。\n",
    "- 这些张量的取值通常应该缩放为较小的值，比如在 [-1, 1] 区间或 [0, 1] 区间。\n",
    "- 如果不同的特征具有不同的取值范围（异质数据），那么应该做数据标准化。\n",
    "- 你可能需要做特征工程，尤其是对于小数据问题。\n",
    "\n",
    "准备好输入数据和目标数据的张量后，你就可以开始训练模型了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.5　开发比基准更好的模型\n",
    "\n",
    "这一阶段的目标是获得统计功效（statistical power），即开发一个小型模型，它能够打败纯\n",
    "随机的基准（dumb baseline）。在 MNIST 数字分类的例子中，任何精度大于 0.1 的模型都可以说\n",
    "具有统计功效；在 IMDB 的例子中，任何精度大于 0.5 的模型都可以说具有统计功效。\n",
    "\n",
    "注意，不一定总是能获得统计功效。如果你尝试了多种合理架构之后仍然无法打败随机基准，\n",
    "那么原因可能是问题的答案并不在输入数据中。要记住你所做的两个假设。\n",
    "\n",
    "- 假设输出是可以根据输入进行预测的。\n",
    "- 假设可用的数据包含足够多的信息，足以学习输入和输出之间的关系。\n",
    "\n",
    "这些假设很可能是错误的，这样的话你需要从头重新开始。\n",
    "\n",
    "如果一切顺利，你还需要选择三个关键参数来构建第一个工作模型。\n",
    "\n",
    "- 最后一层的激活。它对网络输出进行有效的限制。例如，IMDB 分类的例子在最后一层\n",
    "使用了 sigmoid ，回归的例子在最后一层没有使用激活，等等。\n",
    "- 损失函数。它应该匹配你要解决的问题的类型。例如，IMDB 的例子使用 binary_\n",
    "crossentropy 、回归的例子使用 mse ，等等。\n",
    "- 优化配置。你要使用哪种优化器？学习率是多少？大多数情况下，使用 rmsprop 及其\n",
    "默认的学习率是稳妥的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|问题类型| 最后一层激活| 损失函数|\n",
    "| ------ | ------ | ------ | \n",
    "|二分类问题| sigmoid |binary_crossentropy|\n",
    "|多分类、单标签问题| softmax |categorical_crossentropy|\n",
    "|多分类、多标签问题 |sigmoid| binary_crossentropy|\n",
    "|回归到任意值 |无| mse|\n",
    "|回归到 0~1 范围内的值| sigmoid| mse 或 binary_crossentropy|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.6　扩大模型规模：开发过拟合的模型\n",
    "\n",
    "一旦得到了具有统计功效的模型，问题就变成了：模型是否足够强大？它是否具有足够多\n",
    "的层和参数来对问题进行建模？例如，只有单个隐藏层且只有两个单元的网络，在 MNIST 问题\n",
    "上具有统计功效，但并不足以很好地解决问题。请记住，机器学习中无处不在的对立是优化和\n",
    "泛化的对立，理想的模型是刚好在欠拟合和过拟合的界线上，在容量不足和容量过大的界线上。\n",
    "为了找到这条界线，你必须穿过它。\n",
    "\n",
    "要搞清楚你需要多大的模型，就必须开发一个过拟合的模型，这很简单。\n",
    "\n",
    "- (1) 添加更多的层。\n",
    "- (2) 让每一层变得更大。\n",
    "- (3) 训练更多的轮次。\n",
    "\n",
    "要始终监控训练损失和验证损失，以及你所关心的指标的训练值和验证值。如果你发现模\n",
    "型在验证数据上的性能开始下降，那么就出现了过拟合。\n",
    "\n",
    "下一阶段将开始正则化和调节模型，以便尽可能地接近理想模型，既不过拟合也不欠拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.7　模型正则化与调节超参数\n",
    "\n",
    "这一步是最费时间的：你将不断地调节模型、训练、在验证数据上评估（这里不是测试数据）、\n",
    "再次调节模型，然后重复这一过程，直到模型达到最佳性能。你应该尝试以下几项。\n",
    "\n",
    "- 添加 dropout。\n",
    "- 尝试不同的架构：增加或减少层数。\n",
    "- 添加 L1 和 / 或 L2 正则化。\n",
    "- 尝试不同的超参数（比如每层的单元个数或优化器的学习率），以找到最佳配置。\n",
    "- （可选）反复做特征工程：添加新特征或删除没有信息量的特征。\n",
    "\n",
    "请注意：每次使用验证过程的反馈来调节模型，都会将有关验证过程的信息泄露到模型中。\n",
    "如果只重复几次，那么无关紧要；但如果系统性地迭代许多次，最终会导致模型对验证过程过\n",
    "拟合（即使模型并没有直接在验证数据上训练）。这会降低验证过程的可靠性。\n",
    "\n",
    "一旦开发出令人满意的模型配置，你就可以在所有可用数据（训练数据 + 验证数据）上训\n",
    "练最终的生产模型，然后在测试集上最后评估一次。如果测试集上的性能比验证集上差很多，\n",
    "那么这可能意味着你的验证流程不可靠，或者你在调节模型参数时在验证数据上出现了过拟合。\n",
    "在这种情况下，你可能需要换用更加可靠的评估方法，比如重复的 K 折验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
